# ML-Tracker
## Knowledge base
### Stanford Cheatsheet
[CS 230 - Deep Learning](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-convolutional-neural-networks)  
### Sequences  
[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)  
[Character-level recurrent sequence-to-sequence model - Keras Example](https://keras.io/examples/nlp/lstm_seq2seq/)  
[Understanding LSTM Networks](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)  
#### Attention  
[Sequence to Sequence (seq2seq) and Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)  
[Building Seq2Seq LSTM with Luong Attention in Keras for Time Series Forecasting](https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb)  
[A Comprehensive Guide to Attention Mechanism in Deep Learning for Everyone](https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/)  
[Attention Mechanisms in Recurrent Neural Networks (RNNs) With Keras](https://blog.paperspace.com/seq-to-seq-attention-mechanism-keras/)  
[A simple overview of RNN, LSTM and Attention Mechanism](https://medium.com/swlh/a-simple-overview-of-rnn-lstm-and-attention-mechanism-9e844763d07b)  
[seq2seq Part F Encoder Decoder with Bahdanau & Luong  Attention Mechanism.ipynb](https://colab.research.google.com/github/kmkarakaya/ML_tutorials/blob/master/seq2seq_Part_F_Encoder_Decoder_with_Bahdanau_%26_Luong_Attention_Mechanism.ipynb#scrollTo=fm4n9GWCB0mk)  
#### Encoder-Decoders model  
[The encoder-decoder model as a dimensionality reduction technique](https://ekamperi.github.io/machine%20learning/2021/01/21/encoder-decoder-model.html)  
### PCA  
[Essential Math for Data Science: Eigenvectors and application to PCA](https://towardsdatascience.com/essential-math-for-data-science-eigenvectors-and-application-to-pca-6f85d11ceb64)  
### Other  
[6 Types of “Feature Importance” Any Data Scientist Should Know](https://towardsdatascience.com/6-types-of-feature-importance-any-data-scientist-should-master-1bfd566f21c9)  
[Bayesian Optimization with Python](https://towardsdatascience.com/bayesian-optimization-with-python-85c66df711ec)  
## Papers  
[Long Short-Term Memory Recurrent Neural Network Architectures
for Large Scale Acoustic Modeling](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43905.pdf)  
[Auto-encoder based Model for High-dimensional Imbalanced Industrial Data](https://arxiv.org/ftp/arxiv/papers/2108/2108.02083.pdf)  
## Books  
[Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)  
[An Introduction to Statistical Learning](https://static1.squarespace.com/static/5ff2adbe3fe4fe33db902812/t/6009dd9fa7bc363aa822d2c7/1611259312432/ISLR+Seventh+Printing.pdf)  
## DataSets
[Seagate Soft Sensing Data sets](https://github.com/Seagate/softsensing_data)
